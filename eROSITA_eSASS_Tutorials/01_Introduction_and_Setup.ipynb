{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"Flowcharts/Flare_filtering_flowchart.png\" alt=\"plot\" style=\"width:40%;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Input & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"default\")\n",
    "plt.rc('xtick', direction='in', top=True)\n",
    "plt.rc('ytick', direction='in', right=True)\n",
    "plt.rc('axes', linewidth=1.15)\n",
    "\n",
    "plt.rc(\"mathtext\", fontset=\"dejavuserif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "elist = glob.glob('Data/Raw_data/???/???/EXP_010/e?01_??????_020_EventList_c010.fits.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Data/Filtered_data'):\n",
    "    os.system('mkdir Data/Filtered_data')\n",
    "\n",
    "if not os.path.exists('Data/Filtered_data/Lightcurves'):\n",
    "    os.system('mkdir Data/Filtered_data/Lightcurves')\n",
    "\n",
    "if not os.path.exists('Data/Filtered_data/Merged'):\n",
    "    os.system('mkdir Data/Filtered_data/Merged')\n",
    "\n",
    "timebin='20'\n",
    "\n",
    "clean_list = np.empty(len(elist), dtype=object)\n",
    "lightcurve0_list = np.empty(len(elist), dtype=object)\n",
    "lightcurve_list = np.empty(len(elist), dtype=object)\n",
    "filtered_list = np.empty(len(elist), dtype=object)\n",
    "\n",
    "for i in range(len(elist)):\n",
    "    clean_list[i] = 'Data/Filtered_data/'+elist[i].split('/')[-1].replace('EventList_c010.fits.gz','c010_s01_CleanedEvents.fits')\n",
    "    lightcurve0_list[i] = 'Data/Filtered_data/Lightcurves/'+elist[i].split('/')[-1].replace('EventList_c010.fits.gz',f'c010_s02_LC0_tb{timebin}.fits')\n",
    "    lightcurve_list[i] = 'Data/Filtered_data/Lightcurves/'+elist[i].split('/')[-1].replace('EventList_c010.fits.gz',f'c010_s03_LC_tb{timebin}.fits')\n",
    "    filtered_list[i] = 'Data/Filtered_data/'+elist[i].split('/')[-1].replace('EventList_c010.fits.gz','c010_s04_FlareFilteredEvents.fits')\n",
    "\n",
    "with open('Data/crab.list','w') as f:\n",
    "    for e in filtered_list:\n",
    "        f.write(f'{e}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Make clean Event list for all tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evtool(input_name, output_name, gti_type='GTI', flag_type='0xe00fff30', pattern='15', emin='0.2', emax='10.0', image='no', events='yes', telid='1 2 3 4 5 6 7', log_file=None):\n",
    "    subprocess.run(['evtool', \n",
    "                    f'eventfiles={input_name}', \n",
    "                    f'outfile={output_name}', \n",
    "                    f'gti={gti_type}', \n",
    "                    f'flag={flag_type}', \n",
    "                    f'pattern={pattern}', \n",
    "                    f'emin={emin}', \n",
    "                    f'emax={emax}',\n",
    "                    f'image={image}',\n",
    "                    f'events={events}',\n",
    "                    f'telid={telid}'\n",
    "                    ],\n",
    "                    stdout=log_file,\n",
    "                    stderr=log_file)\n",
    "    \n",
    "def run_radec2xy(input_name, ra, dec, log_file=None):\n",
    "    subprocess.run(['radec2xy', \n",
    "                    f'{input_name}', \n",
    "                    f'ra0={ra}', \n",
    "                    f'dec0={dec}'],\n",
    "                    stdout=log_file,\n",
    "                    stderr=log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evtool finished successfully for 4 out of 4 files (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('Data/Filtered_data/evtool_s01.log', 'w+') as log_file:    \n",
    "    for tile in tqdm(range(len(elist))):   \n",
    "        run_evtool(elist[tile], clean_list[tile], log_file=log_file)\n",
    "        # center_ra = fits.getval(clean_list[tile], \"RA_CEN\", ext=1)\n",
    "        # center_dec = fits.getval(clean_list[tile], \"DEC_CEN\", ext=1)\n",
    "        # run_radec2xy(clean_list[tile], center_ra, center_dec, log_file=log_file)\n",
    "\n",
    "    log_file.seek(0)\n",
    "    log_content = log_file.readlines()\n",
    "    evtool_count = sum(1 for line in log_content if 'evtool: DONE' in line)\n",
    "    # radec2xy_count = sum(1 for line in log_content if 'radec2xy: DONE' in line)\n",
    "    print(f'evtool finished successfully for {evtool_count} out of {len(elist)} files ({evtool_count/len(elist)*100}%)')\n",
    "    # print(f'radec2xy finished successfully for {radec2xy_count} out of {len(elist)} files ({radec2xy_count/len(elist)*100}%)')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract the lightcurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_flaregti(input_name, output_lightcurve, pimin='5000', source_size='150', gridsize='26', timebin=timebin, threshold='-1', log_file=None):\n",
    "    subprocess.run(['flaregti', \n",
    "                    f'{input_name}', \n",
    "                    f'pimin={pimin}', \n",
    "                    f'source_size={source_size}',\n",
    "                    f'gridsize={gridsize}',\n",
    "                    f'lightcurve={output_lightcurve}',\n",
    "                    'write_mask=no',\n",
    "                    f'timebin={timebin}',\n",
    "                    f'threshold={threshold}'\n",
    "                    ],\n",
    "                    stdout=log_file,\n",
    "                    stderr=log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flaregti finished successfully for 4 out of 4 files (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('Data/Filtered_data/Lightcurves/flaregti_s02.log', 'w+') as log_file:\n",
    "    for tile in tqdm(range(len(elist))):   \n",
    "        run_flaregti(clean_list[tile], lightcurve0_list[tile], log_file=log_file)\n",
    "    \n",
    "    log_file.seek(0)\n",
    "    log_content = log_file.readlines()\n",
    "    flaregti_count = sum(1 for line in log_content if 'flaregti: DONE' in line)\n",
    "    print(f'flaregti finished successfully for {flaregti_count} out of {len(elist)} files ({flaregti_count/len(elist)*100}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Flare filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, amplitude, mean, stdev):\n",
    "    return amplitude * np.exp(-((x - mean) ** 2) / (2 * stdev**2))\n",
    "\n",
    "def fit_gaussian(data, bins='auto'):\n",
    "    bin_heights, bin_borders = np.histogram(data, bins=bins)\n",
    "    bin_centers = (bin_borders[:-1] + bin_borders[1:]) / 2\n",
    "    popt, pcov = curve_fit(gaussian, bin_centers, bin_heights, p0=[1., np.mean(data), np.std(data)])\n",
    "    return popt, pcov, bin_borders\n",
    "\n",
    "def sigma_clipping(data, popt):\n",
    "    data_std = popt[2]\n",
    "    data_mean = popt[1]\n",
    "    sigma_threshold = data_std * 3\n",
    "    lower_limit  = data_mean - sigma_threshold \n",
    "    upper_limit = data_mean + sigma_threshold\n",
    "    clipped_data = data[(data >= lower_limit) & (data <= upper_limit)]\n",
    "    return clipped_data, lower_limit, upper_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_lightcurve(input_data, image=False, output_dir='Data/Filtered_data/Lightcurves/'):\n",
    "    lightcurve = fits.open(input_data)\n",
    "    time = lightcurve[1].data['TIME']\n",
    "    rate = lightcurve[1].data['RATE']\n",
    "    positive_rate = rate[rate > 0]\n",
    "\n",
    "    popt_rate, pcov_rate, rate_borders = fit_gaussian(rate)\n",
    "    popt_pos, _, _ = fit_gaussian(positive_rate)\n",
    "    clipped_data, lower_limit, upper_limit = sigma_clipping(positive_rate, popt_pos)\n",
    "    popt_clip, pcov_clip, _ = fit_gaussian(clipped_data, bins=rate_borders)\n",
    "\n",
    "    if image:\n",
    "        plt.rc('font', family='DejaVu Serif', size=11)\n",
    "\n",
    "        fig, ax = plt.subplots(3, 1, figsize=(8, 7))\n",
    "        fig.subplots_adjust(hspace=0.4)  \n",
    "\n",
    "        main_color = 'tab:red'\n",
    "        clipping_region_color = 'k'\n",
    "\n",
    "        # Plot 1\n",
    "        ax[0].plot((time - time[0]) / 1e3, rate, lw=1.5, color=main_color)\n",
    "        ax[0].set_ylabel('Rate \\n $[\\mathrm{cts\\ s^{-1}\\ deg^{-2}}]$')\n",
    "        ax[0].set_xlabel('Time [ks]')\n",
    "        ax[0].axhline(popt_rate[1], color=clipping_region_color, linestyle='--', label='Mean')\n",
    "        ax[0].axhspan(lower_limit, upper_limit, color=clipping_region_color, alpha=0.3, label='Clipping Region')\n",
    "        ax[0].legend()\n",
    "\n",
    "        # Plot 2\n",
    "        ax[1].plot(np.arange(0, len(rate)) * 10 / 1e3, rate, lw=1.5, color=main_color)\n",
    "        ax[1].set_ylabel('Rate \\n $[\\mathrm{cts\\ s^{-1}\\ deg^{-2}}]$')\n",
    "        ax[1].set_xlabel('Time [ks]')\n",
    "        ax[1].axhline(popt_rate[1], color=clipping_region_color, linestyle='--', label='Mean')\n",
    "        ax[1].axhspan(lower_limit, upper_limit, color=clipping_region_color, alpha=0.3, label='Clipping Region')\n",
    "        ax[1].legend()\n",
    "\n",
    "        # Plot 3\n",
    "        ax[2].hist(rate, bins=rate_borders, alpha=0.5, label='Data', color=main_color)\n",
    "        x_fit_interval = np.linspace(rate_borders[0], rate_borders[-1], 100)\n",
    "        ax[2].axvspan(lower_limit, upper_limit, color='steelblue', alpha=0.25)\n",
    "        ax[2].hist(clipped_data, bins=rate_borders, alpha=0.75, label='Clipped Data', color='tab:blue')\n",
    "        ax[2].plot(x_fit_interval, gaussian(x_fit_interval, *popt_clip), label='Fitted Gaussian (Clipped)', color='tab:red')\n",
    "\n",
    "        ax[2].set_xlabel('Rate $[\\mathrm{cts\\ s^{-1}\\ deg^{-2}}]$')\n",
    "        ax[2].set_ylabel('Counts')\n",
    "        ax[2].legend()\n",
    "\n",
    "        fig.savefig(output_dir + input_data.split('/')[-1].replace('.fits', '.png'), dpi=300)\n",
    "        plt.close(fig)  # Close the figure to avoid displaying it\n",
    "    \n",
    "    return upper_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.97it/s]\n"
     ]
    }
   ],
   "source": [
    "tile_thresholds = np.zeros(len(lightcurve0_list))\n",
    "for tile in tqdm(range(len(lightcurve0_list))):   \n",
    "    tile_thresholds[tile]=threshold_lightcurve(lightcurve0_list[tile], image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.32333336 1.21836281 1.27990402 1.23849327]\n"
     ]
    }
   ],
   "source": [
    "print(tile_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Re-run `flaregti` with calculated thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flaregti finished successfully for 4 out of 4 files (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('Data/Filtered_data/Lightcurves/flaregti_s03.log', 'w+') as log_file:\n",
    "    for tile in tqdm(range(len(elist))):   \n",
    "        run_flaregti(clean_list[tile], lightcurve_list[tile], threshold = tile_thresholds[tile],log_file=log_file)\n",
    "    \n",
    "    log_file.seek(0)\n",
    "    log_content = log_file.readlines()\n",
    "    flaregti_count = sum(1 for line in log_content if 'flaregti: DONE' in line)\n",
    "    print(f'flaregti finished successfully for {flaregti_count} out of {len(elist)} files ({flaregti_count/len(elist)*100}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Re-run `evtool` using the new GTIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evtool finished successfully for 4 out of 4 files (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('Data/Filtered_data/evtool_s04.log', 'w+') as log_file:    \n",
    "    for tile in tqdm(range(len(elist))):   \n",
    "        run_evtool(clean_list[tile], filtered_list[tile], gti_type=\"FLAREGTI\", log_file=log_file)\n",
    "\n",
    "    log_file.seek(0)\n",
    "    log_content = log_file.readlines()\n",
    "    evtool_count = sum(1 for line in log_content if 'evtool: DONE' in line)\n",
    "    print(f'evtool finished successfully for {evtool_count} out of {len(clean_list)} files ({evtool_count/len(clean_list)*100}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_check = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.1: Proof check for the flare filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if proof_check:\n",
    "    if not os.path.exists('Data/Filtered_data/Lightcurves/Proof_check'):\n",
    "        os.system('mkdir Data/Filtered_data/Lightcurves/Proof_check')\n",
    "\n",
    "    pc_lightcurve_list = np.empty(len(elist), dtype=object)\n",
    "\n",
    "    for i in range(len(filtered_list)):\n",
    "        pc_lightcurve_list[i] = 'Data/Filtered_data/Lightcurves/Proof_check/'+filtered_list[i].split('/')[-1].replace('s04_FlareFilteredEvents.fits',f's041_pcLC_tb{timebin}.fits')\n",
    "\n",
    "    with open('Data/Filtered_data/Lightcurves/Proof_check/flaregti_s041.log', 'w+') as log_file:\n",
    "        for tile in tqdm(range(len(elist))):   \n",
    "            run_flaregti(filtered_list[tile], pc_lightcurve_list[tile], log_file=log_file)\n",
    "        \n",
    "        log_file.seek(0)\n",
    "        log_content = log_file.readlines()\n",
    "        flaregti_count = sum(1 for line in log_content if 'flaregti: DONE' in line)\n",
    "        print(f'flaregti finished successfully for {flaregti_count} out of {len(elist)} files ({flaregti_count/len(elist)*100}%)')\n",
    "\n",
    "    for tile in tqdm(range(len(pc_lightcurve_list))):   \n",
    "        threshold_lightcurve(pc_lightcurve_list[tile], image=True, output_dir='Data/Filtered_data/Lightcurves/Proof_check/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Combine the tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/Filtered_data/Merged/merged_evtool_s05.log', 'w+') as log_file:    \n",
    "    run_evtool('@Data/crab.list', 'Data/Filtered_data/Merged/Merged_020_s05_TM0_Events.fits', gti_type=\"FLAREGTI\", log_file=log_file)\n",
    "    center_ra = '83.63240'\n",
    "    center_dec = '22.01740'\n",
    "    run_radec2xy('Data/Filtered_data/Merged/Merged_020_s05_Events.fits', center_ra, center_dec, log_file=log_file)\n",
    "\n",
    "    log_file.seek(0)\n",
    "    log_content = log_file.readlines()\n",
    "    evtool_count = sum(1 for line in log_content if 'evtool: DONE' in line)\n",
    "    radec2xy_count = sum(1 for line in log_content if 'radec2xy: DONE' in line)\n",
    "    if evtool_count == 1 and radec2xy_count == 1:\n",
    "        print('Merged tiles eventlist successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.1: Separate the merged event list into individual TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evtool successfully separted file into 9 files for 9 TMs (100.0%)\n"
     ]
    }
   ],
   "source": [
    "TM_list = np.array([1,2,3,4,5,6,7])\n",
    "\n",
    "with open('Data/Filtered_data/Merged/separate_TM_evtool_s05.log', 'w+') as log_file:\n",
    "    for i in tqdm(range(len(TM_list))):\n",
    "        run_evtool('Data/Filtered_data/Merged/Merged_020_s05_TM0_Events.fits', f'Data/Filtered_data/Merged/Merged_{TM_list[i]}20_s05_TM{TM_list[i]}_Events.fits', telid=f'{TM_list[i]}', log_file=log_file)\n",
    "\n",
    "    run_evtool('Data/Filtered_data/Merged/Merged_020_s05_TM0_Events.fits', 'Data/Filtered_data/Merged/Merged_820_s05_TM8_Events.fits', telid='1 2 3 4 6', log_file=log_file)\n",
    "\n",
    "    run_evtool('Data/Filtered_data/Merged/Merged_020_s05_TM0_Events.fits', 'Data/Filtered_data/Merged/Merged_920_s05_TM9_Events.fits', telid='5 7', log_file=log_file)\n",
    "\n",
    "    log_file.seek(0)\n",
    "    log_content = log_file.readlines()\n",
    "    evtool_count = sum(1 for line in log_content if 'evtool: DONE' in line)\n",
    "    print(f'evtool successfully separted file into {evtool_count} files for {len(TM_list)+2} TMs ({evtool_count/(len(TM_list)+2)*100}%)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heasoft_6.31",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
